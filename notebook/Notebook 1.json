{
	"name": "Notebook 1",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "487be253-2bb0-4da2-ab6c-b31dca15c58c"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"# Install the following package before running this program\r\n",
					"\r\n",
					" import sys\r\n",
					" !{sys.executable} -m pip install azure-storage-blob\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Load a folder from load to Azure storage. Remove parent part of path."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import os\r\n",
					"from azure.storage.blob import BlobServiceClient\r\n",
					"# Install the following package before running this program\r\n",
					"# pip install azure-storage-blob\r\n",
					"\r\n",
					"def upload_data_to_adls():\r\n",
					"    \"\"\"\r\n",
					"    Function to upload local directory to ADLS\r\n",
					"    :return:\r\n",
					"    \"\"\"\r\n",
					"    # Azure Storage connection string\r\n",
					"    connect_str = \"DefaultEndpointsProtocol=https;AccountName=azstoragepwyjdyjd;AccountKey=ZBoJsPbrX9deZigrzCE4lzIjThj8bagjksLEy+lgMsw7Qc1Lpbgq10ug/f9QwvRHYbvp+1rrIGLq+AStAah/Og==;EndpointSuffix=core.windows.net\"\r\n",
					"    # Name of the Azure container\r\n",
					"    container_name = \"week5\"\r\n",
					"    # The path to be removed from the local directory path while uploading it to ADLS\r\n",
					"    path_to_remove = \"C:\\\\Users\\\\JamesDeng\\\\Downloads\\\\nyc_green_taxi_data\\\\\"\r\n",
					"    # The local directory to upload to ADLS\r\n",
					"    local_path = \"C:\\\\Users\\\\JamesDeng\\\\Downloads\\\\nyc_green_taxi_data\\\\raw\\\\\"\r\n",
					"    \r\n",
					"    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\r\n",
					"    # The below code block will iteratively traverse through the files and directories under the given folder and uploads to ADLS.\r\n",
					"    for r, d, f in os.walk(local_path):\r\n",
					"        if f:\r\n",
					"            for file in f:\r\n",
					"                file_path_on_azure = os.path.join(r, file).replace(path_to_remove, \"\")\r\n",
					"                file_path_on_local = os.path.join(r, file)\r\n",
					"                blob_client = blob_service_client.get_blob_client(container=container_name, blob=file_path_on_azure)\r\n",
					"                with open(file_path_on_local, \"rb\") as data:\r\n",
					"                    blob_client.upload_blob(data)\r\n",
					"                    print(\"uploading file â€”->\", file_path_on_local)\r\n",
					"                \r\n",
					"\r\n",
					"if __name__ == '__main__':\r\n",
					"    # invoking the upload_data_to_adls() function.\r\n",
					"    upload_data_to_adls()"
				],
				"execution_count": null
			}
		]
	}
}